# üöÄ PySpark Big Data Pipeline: An√°lise e Otimiza√ß√£o de Estat√≠sticas do YouTube

**Descri√ß√£o:** Projeto de Big Data ponta a ponta (E2E) desenvolvido em **PySpark** no Google Colab. O pipeline cobre ingest√£o de dados, ETL, An√°lise Explorat√≥ria (EDA), Engenharia de Features para Machine Learning, Modelagem de Regress√£o Linear para previs√£o de Engajamento, e otimiza√ß√£o de performance de Joins e I/O.

## üìã Tabela de Conte√∫do

1. [Vis√£o Geral do Projeto](#1-vis√£o-geral-do-projeto)
2. [Ferramentas e Tecnologias](#2-ferramentas-e-tecnologias)
3. [Estrutura do Pipeline (Etapas)](#3-estrutura-do-pipeline-etapas)
4. [M√≥dulos Notebooks](#4-m√≥dulos-notebooks)
5. [Como Executar o Projeto](#5-como-executar-o-projeto)
6. [Resultados e Conclus√£o](#6-resultados-e-conclus√£o)

---

## 1. Vis√£o Geral do Projeto

Este projeto demonstra a aplica√ß√£o de **PySpark** para processamento e an√°lise de grandes volumes de dados de estat√≠sticas de v√≠deos do YouTube. O foco principal √© simular um pipeline de dados completo, desde a manipula√ß√£o inicial dos arquivos at√© a aplica√ß√£o de t√©cnicas avan√ßadas de Big Data, Machine Learning e otimiza√ß√£o de performance.

## 2. Ferramentas e Tecnologias

| √Årea | Ferramenta / Tecnologia | Uso no Projeto |
| :--- | :--- | :--- |
| **Big Data Framework** | **PySpark (Apache Spark)** | Processamento distribu√≠do, ETL e Computa√ß√£o In-Memory. |
| **Linguagem** | **Python** | Linguagem principal para desenvolvimento. |
| **Ambiente** | **Google Colab** | Ambiente de desenvolvimento e execu√ß√£o (Notebooks Jupyter). |
| **Armazenamento** | **Parquet** | Formato de arquivo colunar otimizado para I/O em Big Data. |
| **An√°lise** | **Spark SQL** | Consultas e opera√ß√µes de transforma√ß√£o de dados. |
| **Machine Learning** | **Spark MLlib** | Engenharia de Features, Regress√£o Linear. |

---

## 3. Estrutura do Pipeline (Etapas)

O projeto foi dividido em etapas modulares, garantindo a rastreabilidade e a organiza√ß√£o do fluxo de trabalho.

### **Fase I: ETL (Extract, Transform, Load) e An√°lise**

| Etapa | Notebook Principal | Habilidades Demonstradas |
| :--- | :--- | :--- |
| **1. Ingest√£o e Armazenamento** | `leitura_escrita.ipynb` | Leitura de dados CSV, infer√™ncia e defini√ß√£o de Schema. **Convers√£o e escrita eficiente** em formato **Parquet**. |
| **2. Tratamento e Transforma√ß√£o** | `tratamento.ipynb` | Manipula√ß√£o de valores nulos (preenchimento com **0** ou remo√ß√£o). Convers√£o de tipos de dados (`Date`, `Integer`). Cria√ß√£o da *feature* **`Interaction`** (Likes + Comments + Views). Jun√ß√£o de m√∫ltiplas fontes de dados (Left Join e Join complexo). |
| **3. An√°lise Explorat√≥ria (EDA) e Agrega√ß√£o** | `agregacao.ipynb` | C√°lculo de estat√≠sticas descritivas (M√©dia, Vari√¢ncia, Max, Min) agrupadas por `Keyword`. An√°lise de tend√™ncias temporais. Aplica√ß√£o de **Window Functions (Fun√ß√µes de Janela)** para calcular m√©dias acumulativas. |

---

### **Fase II: Machine Learning e Otimiza√ß√£o**

| Etapa | Notebook Principal | Habilidades Demonstradas |
| :--- | :--- | :--- |
| **4. Engenharia de Features** | `preparacao.ipynb` | Extra√ß√£o de features temporais (`Year`, `Month`). Codifica√ß√£o de vari√°veis categ√≥ricas (**`StringIndexer`**). Cria√ß√£o de vetor de features (**`VectorAssembler`**). Aplica√ß√£o de **Normaliza√ß√£o** e **Redu√ß√£o de Dimensionalidade (PCA)** nos vetores. |
| **5. Modelagem de Machine Learning** | `preparacao.ipynb` | Treinamento de modelo de **Regress√£o Linear** (`LinearRegression`) para prever o n√∫mero de `Comments` (Engajamento). Avalia√ß√£o do modelo usando m√©trica **RMSE**. |
| **6. Otimiza√ß√£o de Performance** | `otimizacao.ipynb` | Cria√ß√£o de Views Tempor√°rias SQL. Compara√ß√£o de Planos de Execu√ß√£o (`explain(extended=True)`). Demonstra√ß√£o de otimiza√ß√µes de I/O e computa√ß√£o com **Project Pushdown** e **Filter Pushdown**. Controle de particionamento (`coalesce`/`repartition`) para escrita e otimiza√ß√£o do *Small Files Problem*. |

---

## 4. M√≥dulos Notebooks

| Arquivo (`.ipynb`) | Foco Principal |
| :--- | :--- |
| `leitura_escrita.ipynb` | Ingest√£o de dados e convers√£o para Parquet. |
| `tratamento.ipynb` | Limpeza de dados, transforma√ß√µes e jun√ß√£o de m√∫ltiplas fontes. |
| `agregacao.ipynb` | C√°lculos estat√≠sticos, EDA e aplica√ß√£o de Window Functions. |
| `preparacao.ipynb` | Engenharia de Features, Modelagem ML (Regress√£o Linear) e Avalia√ß√£o (RMSE). |
| `otimizacao.ipynb` | T√©cnicas de otimiza√ß√£o de Joins e gerenciamento de parti√ß√µes. |

---

## 5. Como Executar o Projeto

O projeto foi desenvolvido 100% no **Google Colab**.

1.  **Pr√©-requisitos:** Uma conta Google para acesso ao Google Colab.
2.  **Instala√ß√£o:** Todos os notebooks iniciam com a instala√ß√£o da biblioteca PySpark: `!pip install pyspark`.
3.  **Dados:** Os arquivos de dados CSV (n√£o inclu√≠dos no reposit√≥rio final) s√£o necess√°rios e devem ser carregados no ambiente de execu√ß√£o do Colab antes de rodar os notebooks de ETL.
4.  **Ordem de Execu√ß√£o:** Os notebooks devem ser executados sequencialmente para que os arquivos Parquet gerados em uma etapa sejam utilizados na etapa seguinte:
    * `leitura_escrita.ipynb` (Gera arquivos Parquet iniciais)
    * `tratamento.ipynb` (Gera arquivos Parquet tratados, ex: `videos-comments-tratados-parquet`)
    * `preparacao.ipynb` (Gera arquivos Parquet preparados para ML, ex: `videos-preparados-parquet`)
    * `agregacao.ipynb` (L√™ os dados preparados e executa a EDA)
    * `otimizacao.ipynb` (L√™ os dados tratados e os coment√°rios para os testes de Join)

---

## 6. Resultados e Conclus√£o

Este projeto serviu como uma demonstra√ß√£o pr√°tica do poder do PySpark em todas as etapas de um projeto de Big Data. As principais conclus√µes foram:

* A convers√£o para o formato **Parquet** otimizou significativamente o tempo de leitura e a efici√™ncia de armazenamento.
* A aplica√ß√£o de t√©cnicas de **Otimiza√ß√£o (Pushdown)** resultou em planos de execu√ß√£o mais eficientes, fundamentais para a escalabilidade em grandes volumes de dados.
* O pipeline de Engenharia de Features provou ser eficaz para preparar dados n√£o estruturados para um modelo de **Regress√£o Linear**, alcan√ßando um **RMSE** de `43345.23` na previs√£o de Coment√°rios, o que representa um ponto de partida para an√°lises preditivas mais aprofundadas sobre o engajamento de v√≠deos.
